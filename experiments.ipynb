{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import yaml\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from joblib import dump, load\n",
    "import numpy as np\n",
    "\n",
    "# Import configuration file\n",
    "with open(\"config.yaml\") as config_file:\n",
    "    config = yaml.safe_load(config_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the output filenames\n",
    "version_name = config[\"input\"][\"version_name\"]\n",
    "\n",
    "num_iterations = config[\"boosting_parameters\"][\"num_iterations\"]\n",
    "max_depth = config[\"boosting_parameters\"][\"max_depth\"]\n",
    "learning_rate = config[\"boosting_parameters\"][\"learning_rate\"]\n",
    "\n",
    "tag = f\"{version_name}(m={num_iterations},d={max_depth},a={learning_rate})\"\n",
    "\n",
    "model_df_filename = f\"{config[\"output\"][\"model_dump_filename_header\"]}_{tag}.joblib\"\n",
    "train_pred_prob_df_filename = f\"{config[\"output\"][\"train_pred_prob_df_filename_header\"]}_{tag}.csv\"\n",
    "test_pred_prob_df_filename = f\"{config[\"output\"][\"test_pred_prob_df_filename_header\"]}_{tag}.csv\"\n",
    "\n",
    "train_log_loss_filename = f\"{config[\"output\"][\"train_log_loss_filename_header\"]}_{tag}.csv\"\n",
    "test_log_loss_filename = f\"{config[\"output\"][\"test_log_loss_filename_header\"]}_{tag}.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the dataframes\n",
    "train_df = pd.read_csv(config[\"input\"][\"train_df_filename\"], index_col = 0)     # use the pre-existing indices\n",
    "test_df = pd.read_csv(config[\"input\"][\"test_df_filename\"], index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the dataframes as categorized (lost when written to CSV)\n",
    "CATEGORY_COLUMN_NAMES = [\"workclass\", \"education\", \"marital.status\", \"occupation\", \"relationship\", \"race\", \"sex\", \"native.country\", \"income\"]\n",
    "NUMBER_COLUMN_NAMES = [\"age\", \"education.num\", \"capital.gain\", \"capital.loss\", \"hours.per.week\"] # also fnlwgt, technically (but this is not in the frame)\n",
    "\n",
    "# Categorize in place\n",
    "def categorize(df):\n",
    "    for categorical_column_name in CATEGORY_COLUMN_NAMES:\n",
    "        df[categorical_column_name] = df[categorical_column_name].astype('category')\n",
    "\n",
    "categorize(train_df)\n",
    "categorize(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into X and y\n",
    "def get_X_y (df):\n",
    "    return (df.drop(\"income\", axis = 1), df[\"income\"])\n",
    "\n",
    "train_X, train_y = get_X_y(train_df)\n",
    "test_X, test_y = get_X_y(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train boosted classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the boosting classifier with the provided parameters\n",
    "classifier = HistGradientBoostingClassifier(\n",
    "    loss = 'log_loss',\n",
    "    categorical_features = 'from_dtype', \n",
    "    early_stopping = False,\n",
    "\n",
    "    max_iter = num_iterations,\n",
    "    max_depth = max_depth,\n",
    "    learning_rate = learning_rate\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['output-data/model_dump_v1(m=1000,d=1,a=0.1).joblib']"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the classifier on the train data and dump\n",
    "classifier.fit(train_X, train_y)\n",
    "dump(classifier, model_df_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate boosted classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy = 0.8711428571428571\n",
      "Test accuracy = 0.8606666666666667\n"
     ]
    }
   ],
   "source": [
    "# Report final accuracy\n",
    "print(f\"Train accuracy = {classifier.score(train_X, train_y)}\")\n",
    "print(f\"Test accuracy = {classifier.score(test_X, test_y)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute and save the staged predictions. Shape = (n, d, 2) (2 = one for each probability)\n",
    "staged_train_pred_prob = np.array([pred_prob for pred_prob in classifier.staged_predict_proba(train_X)])\n",
    "staged_test_pred_prob = np.array([pred_prob for pred_prob in classifier.staged_predict_proba(test_X)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: figure out how to save a 3D array to a file\n",
    "np.savetxt(train_pred_prob_df_filename, staged_train_pred_prob)\n",
    "np.savetxt(test_pred_prob_df_filename, staged_train_pred_prob)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CS229ProjectEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
